#!/usr/bin/env node
"use strict";
var __createBinding = (this && this.__createBinding) || (Object.create ? (function(o, m, k, k2) {
    if (k2 === undefined) k2 = k;
    var desc = Object.getOwnPropertyDescriptor(m, k);
    if (!desc || ("get" in desc ? !m.__esModule : desc.writable || desc.configurable)) {
      desc = { enumerable: true, get: function() { return m[k]; } };
    }
    Object.defineProperty(o, k2, desc);
}) : (function(o, m, k, k2) {
    if (k2 === undefined) k2 = k;
    o[k2] = m[k];
}));
var __setModuleDefault = (this && this.__setModuleDefault) || (Object.create ? (function(o, v) {
    Object.defineProperty(o, "default", { enumerable: true, value: v });
}) : function(o, v) {
    o["default"] = v;
});
var __importStar = (this && this.__importStar) || (function () {
    var ownKeys = function(o) {
        ownKeys = Object.getOwnPropertyNames || function (o) {
            var ar = [];
            for (var k in o) if (Object.prototype.hasOwnProperty.call(o, k)) ar[ar.length] = k;
            return ar;
        };
        return ownKeys(o);
    };
    return function (mod) {
        if (mod && mod.__esModule) return mod;
        var result = {};
        if (mod != null) for (var k = ownKeys(mod), i = 0; i < k.length; i++) if (k[i] !== "default") __createBinding(result, mod, k[i]);
        __setModuleDefault(result, mod);
        return result;
    };
})();
Object.defineProperty(exports, "__esModule", { value: true });
const dotenv = __importStar(require("dotenv"));
const database_adapter_1 = require("../database/database-adapter");
const template_repository_1 = require("../templates/template-repository");
const batch_processor_1 = require("../templates/batch-processor");
dotenv.config();
async function testBatchProcessing() {
    console.log('ğŸ§ª Testing full batch processing with OpenAI Batch API...\n');
    if (!process.env.OPENAI_API_KEY) {
        console.error('âŒ OPENAI_API_KEY not set in environment');
        process.exit(1);
    }
    try {
        const db = await (0, database_adapter_1.createDatabaseAdapter)('./data/nodes.db');
        const repository = new template_repository_1.TemplateRepository(db);
        const batchSize = parseInt(process.env.TEST_BATCH_SIZE || '10');
        const templates = repository.getTemplatesWithoutMetadata(batchSize);
        if (templates.length === 0) {
            console.log('âœ… All templates already have metadata');
            return;
        }
        console.log(`ğŸ“Š Found ${templates.length} templates to process in batch\n`);
        const processor = new batch_processor_1.BatchProcessor({
            apiKey: process.env.OPENAI_API_KEY,
            model: process.env.OPENAI_MODEL || 'gpt-4o-mini',
            batchSize: parseInt(process.env.OPENAI_BATCH_SIZE || '100'),
            outputDir: './temp/batch'
        });
        const requests = templates.map(t => {
            let workflow = null;
            try {
                if (t.workflow_json_compressed) {
                    const decompressed = Buffer.from(t.workflow_json_compressed, 'base64');
                    workflow = JSON.parse(require('zlib').gunzipSync(decompressed).toString());
                }
                else if (t.workflow_json) {
                    workflow = JSON.parse(t.workflow_json);
                }
            }
            catch (e) {
                console.warn(`Failed to parse workflow for template ${t.id}`);
            }
            return {
                templateId: t.id,
                name: t.name,
                description: t.description,
                nodes: JSON.parse(t.nodes_used),
                workflow
            };
        });
        console.log('ğŸ“¤ Submitting batch to OpenAI...');
        console.log('   Note: Batch processing can take 2-24 hours to complete\n');
        const results = await processor.processTemplates(requests, (message, current, total) => {
            process.stdout.write(`\rğŸ“Š ${message}: ${current}/${total}`);
        });
        console.log('\n\nâœ… Batch processing complete!\n');
        const metadataMap = new Map();
        let successCount = 0;
        let errorCount = 0;
        for (const [templateId, result] of results) {
            if (!result.error) {
                metadataMap.set(templateId, result.metadata);
                successCount++;
            }
            else {
                console.warn(`   âš ï¸ Template ${templateId}: ${result.error}`);
                errorCount++;
            }
        }
        if (metadataMap.size > 0) {
            repository.batchUpdateMetadata(metadataMap);
            console.log(`ğŸ’¾ Updated metadata for ${metadataMap.size} templates`);
        }
        console.log('\nğŸ“ˆ Batch Processing Results:');
        console.log(`   - Templates processed: ${templates.length}`);
        console.log(`   - Successful: ${successCount}`);
        console.log(`   - Errors: ${errorCount}`);
        const stats = repository.getMetadataStats();
        console.log('\nğŸ“Š Overall Metadata Statistics:');
        console.log(`   - Total templates: ${stats.total}`);
        console.log(`   - With metadata: ${stats.withMetadata}`);
        console.log(`   - Without metadata: ${stats.withoutMetadata}`);
        console.log(`   - Progress: ${Math.round((stats.withMetadata / stats.total) * 100)}%`);
        if ('close' in db && typeof db.close === 'function') {
            db.close();
        }
    }
    catch (error) {
        console.error('\nâŒ Error:', error);
        process.exit(1);
    }
}
console.log('â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•');
console.log('                  OpenAI Batch API Test                        ');
console.log('â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•');
console.log();
console.log('This test will:');
console.log('1. Create a batch request file (JSONL format)');
console.log('2. Upload it to OpenAI');
console.log('3. Create a batch job');
console.log('4. Monitor the job until completion');
console.log('5. Retrieve and save results to database');
console.log();
console.log('âš ï¸  Note: Batch jobs can take 2-24 hours to complete');
console.log('    but typically finish much faster for small batches');
console.log();
console.log('â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n');
testBatchProcessing().catch(console.error);
//# sourceMappingURL=test-batch-processing.js.map